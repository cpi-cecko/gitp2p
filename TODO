Current:
  0. Refactor `list' functionality
    -- Unify ref sending format
        join ':', (<ref_name> . '?' . <ref_sha>) ALWAYS!!!
  1. Rework `fetch' functionality
    -- Figure out an algorithm for communicating wants/haves. It should lock 
       peers in process of receiving objects.
  2. Write tests:
    -- Cloning a repo from many peers
    -- Fetching an update from a single peer
    -- Fetching an update from many peers while all have the full history
    -- Fetching an update from many peers while all are ahead of you, but
       not all have the full history
    -- Fetching an update from many peers while some of them are behind you, 
       some of them ahead
    -- Fetching a repo while someone is cloning
    -- Cloning a repo while someone is fetching
  3. Write RAW tests for protocol (Just flood the relay with various messages 
      and inspect the result)

-------------------------------------------------------------------------------
Peer-to-peer:
  1. Metainfo file
  2. Make the relay just a peer? A peer could opt for being a relay via some
      config file. Each relay-peer could have some kind of trust points.
  3. Pruning inactive peers
  4. Prioritize rare pieces
  5. Cloning a repo while peer has a partial info about it
  6. After discovery of the initial network peer, we should be able to rely on
     peers instead of a relay.
  7. Object transfer
      - Pack files limited in size, generated on-the-fly
      - Big objects
      - Advertising list of available pack files and determining what a peer 
        needs

git-specific:
  1. Handle alternatives

Security:
  1. Handshake before connections
  2. Trusted updates of branches and tags
  3. Peer impersonation exploit
  4. Uniquely identifiable repositories

Others:
  1. gitp2p-config gets moved a lot
  2. Use JSON::XS with Encode

Ideas:
  1. Torrent tracker web interface
  2. Repo for signed docs
  3. Tool to collect statistics about the network - repos, active peers, etc.
